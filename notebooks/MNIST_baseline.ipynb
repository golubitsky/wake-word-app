{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST exploratory.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EliNyCbodRtH"
      },
      "source": [
        "# Based on https://keras.io/examples/vision/mnist_convnet/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjaUSoa7dYKX"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ99oAfSdYbW",
        "outputId": "069ae590-528e-4751-b9f2-8f68184fd3c8"
      },
      "source": [
        "# Model / data parameters\n",
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "# Make sure images have shape (28, 28, 1)\n",
        "x_train = np.expand_dims(x_train, -1)\n",
        "x_test = np.expand_dims(x_test, -1)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(x_train.shape[0], \"train samples\")\n",
        "print(x_test.shape[0], \"test samples\")\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I58ARG8daRx",
        "outputId": "a2019c1a-4e62-480d-aac2-47cf97e8aac5"
      },
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1600)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                16010     \n",
            "=================================================================\n",
            "Total params: 34,826\n",
            "Trainable params: 34,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gW8I1qHldckO",
        "outputId": "c587b1e3-45c0-4e33-9cbc-70462067c5d3"
      },
      "source": [
        "batch_size = 128\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "422/422 [==============================] - 17s 4ms/step - loss: 0.3585 - accuracy: 0.8941 - val_loss: 0.0859 - val_accuracy: 0.9770\n",
            "Epoch 2/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1100 - accuracy: 0.9665 - val_loss: 0.0544 - val_accuracy: 0.9850\n",
            "Epoch 3/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0826 - accuracy: 0.9749 - val_loss: 0.0467 - val_accuracy: 0.9872\n",
            "Epoch 4/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0698 - accuracy: 0.9776 - val_loss: 0.0407 - val_accuracy: 0.9887\n",
            "Epoch 5/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0600 - accuracy: 0.9814 - val_loss: 0.0384 - val_accuracy: 0.9900\n",
            "Epoch 6/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0539 - accuracy: 0.9828 - val_loss: 0.0371 - val_accuracy: 0.9902\n",
            "Epoch 7/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0493 - accuracy: 0.9850 - val_loss: 0.0379 - val_accuracy: 0.9895\n",
            "Epoch 8/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0477 - accuracy: 0.9848 - val_loss: 0.0337 - val_accuracy: 0.9902\n",
            "Epoch 9/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0420 - accuracy: 0.9867 - val_loss: 0.0340 - val_accuracy: 0.9912\n",
            "Epoch 10/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.9867 - val_loss: 0.0315 - val_accuracy: 0.9917\n",
            "Epoch 11/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0385 - accuracy: 0.9874 - val_loss: 0.0305 - val_accuracy: 0.9917\n",
            "Epoch 12/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0373 - accuracy: 0.9881 - val_loss: 0.0288 - val_accuracy: 0.9910\n",
            "Epoch 13/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.0298 - val_accuracy: 0.9915\n",
            "Epoch 14/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0337 - accuracy: 0.9894 - val_loss: 0.0316 - val_accuracy: 0.9910\n",
            "Epoch 15/15\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.0331 - accuracy: 0.9888 - val_loss: 0.0287 - val_accuracy: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff0c508bd10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCCnW95hdgFe",
        "outputId": "52040683-e38d-4512-92ff-5a470b9329d2"
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.024972835555672646\n",
            "Test accuracy: 0.991599977016449\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqU49m_FguOa",
        "outputId": "f64c665e-0d8b-4102-cf14-04b8c76fdb25"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "# The path below should point to the directory containing this notebook and the associated utility files\n",
        "# Change it if necessary\n",
        "os.chdir('/content/drive/My Drive/FourthBrain/Capstone MNIST')\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "'MNIST exploratory.ipynb'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iurQm-JseDrm"
      },
      "source": [
        "Identify the dependencies required to serve the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xVaCuwfmJs2",
        "outputId": "6ef0e684-e9b3-4931-dd6f-3c6aade62a61"
      },
      "source": [
        "!pip freeze | grep keras\n",
        "!pip freeze | grep numpy\n",
        "!pip freeze | grep tensor"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras-nightly==2.5.0.dev2021032900\n",
            "keras-vis==0.4.1\n",
            "numpy==1.19.5\n",
            "tensorboard==2.5.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.5.0\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.5.0\n",
            "tensorflow-gcs-config==2.5.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==1.0.0\n",
            "tensorflow-probability==0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eyVIPHxgEEa",
        "outputId": "3b5bef76-7f87-499f-9047-afc75d8d5621"
      },
      "source": [
        "file_path = 'keras_model.h5'\n",
        "model.save(file_path)\n",
        "loaded_model = keras.models.load_model(file_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "keras-nightly==2.5.0.dev2021032900\n",
            "keras-vis==0.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRKD2X_Vd76E"
      },
      "source": [
        "Sanity check the model prediction on a random sample."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "_gKkBJoSh9Pa",
        "outputId": "d34b55a1-fff8-4407-8650-c3ab62167d0d"
      },
      "source": [
        "sample = x_test[57]\n",
        "print(sample.shape)\n",
        "# https://stackoverflow.com/a/43019294/3833166\n",
        "x = np.expand_dims(sample, axis=0)\n",
        "print(np.argmax(loaded_model.predict(x)))\n",
        "\n",
        "plt.imshow(sample.reshape((28, 28)), cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vr5ih471dk49"
      },
      "source": [
        "The following code is used, from the test set, to identify and save 2 samples of each class as PNG files. These PNG files will be used to demonstrate the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1MyiSyQHJUH"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def is_done(dictionary):\n",
        "  if len(dictionary) < 10:\n",
        "    return False\n",
        "\n",
        "  for items in dictionary.values():\n",
        "    if len(items) < 2:\n",
        "      return False\n",
        "\n",
        "  return True\n",
        "\n",
        "# find and save 2 of each sample as png images\n",
        "indexes_by_class_label = defaultdict(list)\n",
        "found = set()\n",
        "for index, one_hot_label in enumerate(y_test):\n",
        "  class_label = np.argmax(one_hot_label)\n",
        "\n",
        "  if len(indexes_by_class_label[class_label]) < 2:\n",
        "    indexes_by_class_label[class_label].append(index)\n",
        "\n",
        "  if is_done(indexes_by_class_label):\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "xyA6jUUAHKt9",
        "outputId": "fdcfbccf-40cd-4302-93d6-84a88d3907bc"
      },
      "source": [
        "def save_image(class_label, sample, sample_index):\n",
        "  fig.patch.set_visible(False)\n",
        "  plt.gca().axison = False\n",
        "  plt.imshow(sample.reshape((28, 28)), cmap='gray')\n",
        "  plt.savefig(f'samples/{class_label}_sample_{sample_index}', bbox_inches='tight', pad_inches=0)\n",
        "    \n",
        "\n",
        "for class_label, indexes in indexes_by_class_label.items():\n",
        "  for sample_index, index_in_test_set in enumerate(indexes):\n",
        "    save_image(class_label, x_test[index_in_test_set], sample_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}